{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcMaVRHyS2Gw",
        "outputId": "7345ab0a-f65d-42fd-8782-d5451daf7945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#구글 드라이브와 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLZBYHVpvW8V",
        "outputId": "c6e1bc41-cc59-4505-dde2-bb9d4a650008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry-sdk-1.9.6.tar.gz (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 69.4 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 61.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 73.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 62.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 56.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ced60232fee63d79a7f88e8d2dec6c735bdb3ca936748fe7fe9ff930f2125c4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.16.6-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.0.2)\n",
            "Collecting voxel51-eta<0.9,>=0.8\n",
            "  Downloading voxel51_eta-0.8.0-py2.py3-none-any.whl (563 kB)\n",
            "\u001b[K     |████████████████████████████████| 563 kB 60.3 MB/s \n",
            "\u001b[?25hCollecting pymongo<4,>=3.11\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 58.0 MB/s \n",
            "\u001b[?25hCollecting sseclient-py<2,>=1.7.2\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from fiftyone) (4.1.2.30)\n",
            "Collecting motor<3,>=2.3\n",
            "  Downloading motor-2.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from fiftyone) (2022.2.1)\n",
            "Collecting starlette==0.16.0\n",
            "  Downloading starlette-0.16.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 330 kB/s \n",
            "\u001b[?25hCollecting universal-analytics-python3<2,>=1.0.1\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting pprintpp\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting dacite>=1.6.0\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.8.10)\n",
            "Collecting sse-starlette<1,>=0.10.3\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Collecting fiftyone-brain<0.10,>=0.9\n",
            "  Downloading fiftyone_brain-0.9.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting argcomplete\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting Jinja2>=3\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 69.9 MB/s \n",
            "\u001b[?25hCollecting mongoengine==0.20.0\n",
            "  Downloading mongoengine-0.20.0-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (7.1.2)\n",
            "Collecting hypercorn>=0.13.2\n",
            "  Downloading Hypercorn-0.14.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.3.5)\n",
            "Collecting eventlet\n",
            "  Downloading eventlet-0.33.1-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.16.0)\n",
            "Collecting fiftyone-db<0.4,>=0.3\n",
            "  Downloading fiftyone_db-0.3.0-py3-none-manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting ndjson\n",
            "  Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.64-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.18.3)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (5.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from fiftyone) (6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fiftyone) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.21.6)\n",
            "Collecting retrying\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting strawberry-graphql==0.96.0\n",
            "  Downloading strawberry_graphql-0.96.0-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from fiftyone) (5.4.8)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiftyone) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fiftyone) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from starlette==0.16.0->fiftyone) (4.1.1)\n",
            "Collecting anyio<4,>=3.0.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.96.0->fiftyone) (2.6.1)\n",
            "Collecting graphql-core<3.2.0,>=3.1.0\n",
            "  Downloading graphql_core-3.1.7-py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting backports.cached-property<2.0.0,>=1.0.1\n",
            "  Downloading backports.cached_property-1.0.2-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: click<9.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.96.0->fiftyone) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.96.0->fiftyone) (2.8.2)\n",
            "Collecting sentinel<0.4.0,>=0.3.0\n",
            "  Downloading sentinel-0.3.0-py3-none-any.whl (6.0 kB)\n",
            "Collecting python-multipart<0.0.6,>=0.0.5\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.16.0->fiftyone) (2.10)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from fiftyone-brain<0.10,>=0.9->fiftyone) (1.7.3)\n",
            "Collecting wsproto>=0.14.0\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n",
            "Collecting priority\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting h2>=3.1.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting h11\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.14->fiftyone) (8.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.14->fiftyone) (1.15.0)\n",
            "Collecting httpx>=0.10.0\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting httpcore<0.16.0,>=0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.6.15)\n",
            "Collecting h11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8->fiftyone) (1.24.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8->fiftyone) (1.5.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8->fiftyone) (0.3.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8->fiftyone) (4.12.0)\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8->fiftyone) (2.23.0)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8->fiftyone) (0.7)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->voxel51-eta<0.9,>=0.8->fiftyone) (3.8.1)\n",
            "Collecting botocore<1.28.0,>=1.27.64\n",
            "  Downloading botocore-1.27.64-py3-none-any.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 74.8 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.7/dist-packages (from eventlet->fiftyone) (1.1.3)\n",
            "Collecting dnspython>=1.15.0\n",
            "  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->voxel51-eta<0.9,>=0.8->fiftyone) (3.0.4)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.6.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (1.1.0)\n",
            "Building wheels for collected packages: python-multipart, retrying\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=44b7726f944138519e296de65f7f8a5829da10d9615128ff87b97bdf9d8561f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11447 sha256=cfbc9e13b8c7447dc1bb63006051f2c7b029048e8642dcdab8ed48e3f5718c8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
            "Successfully built python-multipart retrying\n",
            "Installing collected packages: sniffio, urllib3, rfc3986, jmespath, h11, anyio, hyperframe, httpcore, hpack, botocore, wsproto, starlette, sentinel, s3transfer, retrying, python-multipart, pymongo, priority, patool, ndjson, httpx, h2, graphql-core, dnspython, backports.cached-property, argcomplete, xmltodict, voxel51-eta, universal-analytics-python3, strawberry-graphql, sseclient-py, sse-starlette, pprintpp, motor, mongoengine, kaleido, Jinja2, hypercorn, fiftyone-db, fiftyone-brain, eventlet, Deprecated, dacite, boto3, aiofiles, fiftyone\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.2.0\n",
            "    Uninstalling pymongo-4.2.0:\n",
            "      Successfully uninstalled pymongo-4.2.0\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.13 Jinja2-3.1.2 aiofiles-0.8.0 anyio-3.6.1 argcomplete-2.0.0 backports.cached-property-1.0.2 boto3-1.24.64 botocore-1.27.64 dacite-1.6.0 dnspython-2.2.1 eventlet-0.33.1 fiftyone-0.16.6 fiftyone-brain-0.9.0 fiftyone-db-0.3.0 graphql-core-3.1.7 h11-0.12.0 h2-4.1.0 hpack-4.0.0 httpcore-0.15.0 httpx-0.23.0 hypercorn-0.14.1 hyperframe-6.0.1 jmespath-1.0.1 kaleido-0.2.1 mongoengine-0.20.0 motor-2.5.1 ndjson-0.3.1 patool-1.12 pprintpp-0.4.0 priority-2.0.0 pymongo-3.12.3 python-multipart-0.0.5 retrying-1.3.3 rfc3986-1.5.0 s3transfer-0.6.0 sentinel-0.3.0 sniffio-1.2.0 sse-starlette-0.10.3 sseclient-py-1.7.2 starlette-0.16.0 strawberry-graphql-0.96.0 universal-analytics-python3-1.1.1 urllib3-1.25.11 voxel51-eta-0.8.0 wsproto-1.2.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "#패키지 설치\n",
        "!pip install wandb #모델성능시각화\n",
        "!pip install opencv-python-headless==4.1.2.30 #컴퓨터비전\n",
        "!pip install fiftyone #오픈데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYSqMJ7ovXsN",
        "outputId": "a38390cd-065f-4011-a1c2-6dbe6ea4343b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migrating database to v0.16.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.16.6\n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPq-ZZRctH5e",
        "outputId": "45903e15-2fc8-40b7-ba81-bb3a7850c626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_yolov5\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12130, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 12130 (delta 45), reused 54 (delta 26), pack-reused 12047\u001b[K\n",
            "Receiving objects: 100% (12130/12130), 12.59 MiB | 9.81 MiB/s, done.\n",
            "Resolving deltas: 100% (8333/8333), done.\n",
            "/content/drive/MyDrive/test_yolov5/yolov5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.64.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.8.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 38)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 39)) (5.4.8)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.25.11)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.1.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.47.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.35.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 38)) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 38)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 38)) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 38)) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 38)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 38)) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 38)) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 38)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 38)) (0.7.0)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.1 thop-0.1.1.post2207130030\n"
          ]
        }
      ],
      "source": [
        "#yolov5 깃허브 레파지토리를 적절한 위치에 다운로드하고\n",
        "#구글드라이브 내 적절한 위치에서 requirement.txt의 package를 한 번에 import한다.\n",
        "%cd /content/drive/MyDrive/test_yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd /content/drive/MyDrive/test_yolov5/yolov5\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5tcO61hpK4E",
        "outputId": "2682e6ed-6cd1-49ce-c5dd-781b8c86fd73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    4.8Gb/4.8Gb [4.9s elapsed, 0s remaining, 1.1Gb/s]        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    4.8Gb/4.8Gb [4.9s elapsed, 0s remaining, 1.1Gb/s]        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmphzlmm9kx/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmphzlmm9kx/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-bbox.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-bbox.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only found 172 (<4000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.utils.openimages:Only found 172 (<4000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 172 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 172 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████████| 172/172 [12.8s elapsed, 0s remaining, 15.1 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████████| 172/172 [12.8s elapsed, 0s remaining, 15.1 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 images, downloading the remaining 199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Found 1 images, downloading the remaining 199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████████| 199/199 [15.1s elapsed, 0s remaining, 11.9 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████████| 199/199 [15.1s elapsed, 0s remaining, 11.9 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only found 95 (<4000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.utils.openimages:Only found 95 (<4000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 95 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 95 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████████| 95/95 [7.3s elapsed, 0s remaining, 14.5 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████████| 95/95 [7.3s elapsed, 0s remaining, 14.5 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation/metadata/image_ids.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation/metadata/classes.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpdft55h4_/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpdft55h4_/metadata/hierarchy.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation/labels/detections.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only found 9 (<1000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.utils.openimages:Only found 9 (<1000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 9 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 9 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████████████| 9/9 [1.1s elapsed, 0s remaining, 8.4 files/s]         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████████████| 9/9 [1.1s elapsed, 0s remaining, 8.4 files/s]         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only found 105 (<300) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.utils.openimages:Only found 105 (<300) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 105 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 105 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████████| 105/105 [7.6s elapsed, 0s remaining, 12.6 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████████| 105/105 [7.6s elapsed, 0s remaining, 12.6 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only found 3 (<1000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.utils.openimages:Only found 3 (<1000) samples matching your requirements\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 3 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████████████| 3/3 [502.6ms elapsed, 0s remaining, 6.7 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████████████| 3/3 [502.6ms elapsed, 0s remaining, 6.7 files/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6/info.json'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fiftyone.zoo.datasets.ZooDatasetInfo at 0x7f84d07c9850>,\n",
              " '/content/drive/MyDrive/test_yolov5/proto_data/open-images-v6')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#제공된 데이터셋에는 이미 이 코드로 다운받은 데이터가 포함돼있으므로 특별한 경우가 아니라면 이 코드를 실행할 필요는 없음\n",
        "#오픈데이터셋 다운로드: Book은 원격시험감독 목적과 관계없는 데이터가 너무 많아 제외하였고, Postit은 없음\n",
        "\n",
        "fo.config.dataset_zoo_dir = \"/content/drive/MyDrive/test_yolov5/proto_data\"\n",
        "foz.download_zoo_dataset(\"open-images-v6\", split= \"train\",label_types = [\"detections\"], classes = [\"Calculator\"], max_samples = 4000, shuffle = True)\n",
        "foz.download_zoo_dataset(\"open-images-v6\", split= \"train\",label_types = [\"detections\"], classes = [\"Mobile phone\"], max_samples = 200, shuffle = True)\n",
        "foz.download_zoo_dataset(\"open-images-v6\", split= \"train\",label_types = [\"detections\"], classes = [\"Pencil case\"], max_samples = 4000, shuffle = True)\n",
        "\n",
        "foz.download_zoo_dataset(\"open-images-v6\", split= \"validation\",label_types = [\"detections\"], classes = [\"Calculator\"], max_samples = 1000, shuffle = True)\n",
        "foz.download_zoo_dataset(\"open-images-v6\", split= \"validation\",label_types = [\"detections\"], classes = [\"Mobile phone\"], max_samples = 300, shuffle = True)\n",
        "foz.download_zoo_dataset(\"open-images-v6\", split= \"validation\",label_types = [\"detections\"], classes = [\"Pencil case\"], max_samples = 1000, shuffle = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgmZM-8EpPlP",
        "outputId": "2346f5ca-8810-48ea-8e3e-f885a6c5b9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_yolov5/proto_data\n",
            "Loading 'open-images-v6' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'open-images-v6' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 466/466 [1.6s elapsed, 0s remaining, 287.7 samples/s]         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 466/466 [1.6s elapsed, 0s remaining, 287.7 samples/s]         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'open-images-v6' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'open-images-v6' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 117/117 [542.4ms elapsed, 0s remaining, 215.7 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 117/117 [542.4ms elapsed, 0s remaining, 215.7 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'open-images-v6-train-validation' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'open-images-v6-train-validation' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/drive/MyDrive/test_yolov5/proto_data' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.core.collections:Directory '/content/drive/MyDrive/test_yolov5/proto_data' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0% ||----------------|   0/466 [10.8ms elapsed, ? remaining, ? samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Person' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human ear' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human hand' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Tablet computer' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   4% |\\----------------|  18/466 [1.6s elapsed, 39.0s remaining, 11.5 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Watch' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Ring binder' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Pen' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Coin' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Toy' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Tool' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Box' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   5% ||----------------|  25/466 [1.7s elapsed, 30.0s remaining, 14.7 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Digital clock' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Man' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Clothing' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Power plugs and sockets' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  14% |██---------------|  65/466 [2.4s elapsed, 13.5s remaining, 58.8 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Plant' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Laptop' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  17% |██|--------------|  78/466 [2.6s elapsed, 11.7s remaining, 60.3 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Computer keyboard' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Fashion accessory' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Handbag' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Animal' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human face' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  20% |███--------------|  91/466 [2.8s elapsed, 10.4s remaining, 60.0 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Drink' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  25% |████-------------| 115/466 [3.2s elapsed, 8.9s remaining, 57.0 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Tie' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Suit' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Footwear' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Jeans' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Glasses' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human hair' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human head' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human arm' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human body' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Woman' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Mammal' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Girl' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  32% |█████\\-----------| 148/466 [3.8s elapsed, 7.3s remaining, 56.9 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Helmet' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Computer monitor' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Ipod' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  44% |███████|---------| 206/466 [4.8s elapsed, 5.3s remaining, 59.3 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Furniture' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  45% |███████/---------| 210/466 [4.9s elapsed, 5.3s remaining, 57.6 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Billboard' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Poster' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  48% |████████|--------| 225/466 [5.3s elapsed, 5.4s remaining, 47.3 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Desk' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Camera' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Car' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  51% |████████---------| 236/466 [5.5s elapsed, 5.2s remaining, 45.7 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Dress' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Bottle' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  56% |█████████--------| 263/466 [6.0s elapsed, 4.4s remaining, 47.8 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Wine glass' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Beer' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Cocktail' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  60% |██████████/------| 281/466 [6.3s elapsed, 3.6s remaining, 56.9 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Mug' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Coffee cup' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  67% |███████████\\-----| 311/466 [7.0s elapsed, 3.3s remaining, 48.2 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Sculpture' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Food' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Jacket' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  71% |████████████-----| 332/466 [7.3s elapsed, 2.7s remaining, 51.3 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Spoon' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Luggage and bags' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  76% |████████████/----| 354/466 [7.6s elapsed, 2.1s remaining, 56.0 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Cassette deck' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Chopsticks' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  83% |██████████████---| 385/466 [8.2s elapsed, 1.4s remaining, 61.5 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Table' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  86% |██████████████|--| 399/466 [8.4s elapsed, 1.1s remaining, 62.2 samples/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Sunglasses' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  90% |███████████████\\-| 418/466 [8.7s elapsed, 834.6ms remaining, 58.8 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Musical keyboard' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Corded phone' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Computer mouse' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Fax' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Lipstick' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  97% |████████████████|| 450/466 [9.2s elapsed, 266.5ms remaining, 60.5 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Flower' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 466/466 [9.5s elapsed, 0s remaining, 60.2 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Coffee table' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "INFO:eta.core.utils: 100% |█████████████████| 466/466 [9.5s elapsed, 0s remaining, 60.2 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/drive/MyDrive/test_yolov5/proto_data' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.core.collections:Directory '/content/drive/MyDrive/test_yolov5/proto_data' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   4% |/----------------|   5/117 [124.1ms elapsed, 2.8s remaining, 40.3 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human nose' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human mouth' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  14% |██\\--------------|  16/117 [332.9ms elapsed, 2.1s remaining, 48.1 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human eye' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  26% |████-------------|  31/117 [651.1ms elapsed, 1.8s remaining, 47.6 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Remote control' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  42% |███████/---------|  49/117 [986.5ms elapsed, 1.4s remaining, 49.7 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Clock' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Land vehicle' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Window' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Vehicle registration plate' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Tree' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Human leg' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  56% |█████████|-------|  65/117 [1.3s elapsed, 1.0s remaining, 50.2 samples/s]    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Boy' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  83% |██████████████/--|  97/117 [1.9s elapsed, 373.3ms remaining, 54.0 samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Office supplies' not in provided classes\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 117/117 [2.5s elapsed, 0s remaining, 42.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Glove' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/fiftyone/utils/yolo.py:968: UserWarning: Ignoring detection with label 'Baked goods' not in provided classes\n",
            "  warnings.warn(msg)\n",
            "INFO:eta.core.utils: 100% |█████████████████| 117/117 [2.5s elapsed, 0s remaining, 42.4 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "#제공된 데이터셋에는 이미 이 코드로 다운받은 데이터가 포함돼있으므로 특별한 경우가 아니라면 이 코드를 실행할 필요는 없음\n",
        "\n",
        "# 받은 데이터셋을 로드\n",
        "%cd /content/drive/MyDrive/test_yolov5/proto_data\n",
        "dataset_all = foz.load_zoo_dataset(\"open-images-v6\",splits= [\"train\", \"validation\"],label_types = [\"detections\"], download_if_necessary=False)\n",
        "\n",
        "#yolo용 데이터셋을 만듦\n",
        "export_dir = \"/content/drive/MyDrive/test_yolov5/proto_data\"\n",
        "splits = [\"train\", \"validation\"]\n",
        "splits_yolo = [\"train\", \"val\"]\n",
        "classes= [\"Book\", \"Pencil case\", \"Mobile phone\", \"Calculator\", \"Postit\"]\n",
        "for i in (0,1):\n",
        "    split_view = dataset_all.match_tags(splits[i])\n",
        "    split_view.export(\n",
        "        export_dir=export_dir,\n",
        "        dataset_type=fo.types.YOLOv5Dataset,\n",
        "        split=splits_yolo[i],\n",
        "        classes=classes,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dw764-Qlw3ht"
      },
      "outputs": [],
      "source": [
        "#이 코드는 로컬의 데이터를 /content/drive/MyDrive/test_yolov5/proto_data/에 모두 업로드한 뒤 실행함\n",
        "#디렉터리를 만들어준 후 모바일 클라이언트 환경에서 작동할 수 있게 640 * 480으로 resize해줌\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def createFolder(directory):\n",
        "  try:\n",
        "    if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "  except OSError:\n",
        "    print('Error: Creating directory. ' + directory)\n",
        "createFolder('/content/drive/MyDrive/test_yolov5/data')\n",
        "createFolder('/content/drive/MyDrive/test_yolov5/data/images')\n",
        "createFolder('/content/drive/MyDrive/test_yolov5/data/images/train')\n",
        "createFolder('/content/drive/MyDrive/test_yolov5/data/images/val')\n",
        "createFolder('/content/drive/MyDrive/test_yolov5/data/labels')\n",
        "createFolder('/content/drive/MyDrive/test_yolov5/data/labels/train')\n",
        "createFolder('/content/drive/MyDrive/test_yolov5/data/labels/val')\n",
        "\n",
        "\n",
        "train_files = glob.glob('/content/drive/MyDrive/test_yolov5/proto_data/images/train/*.jpg')\n",
        "val_files = glob.glob('/content/drive/MyDrive/test_yolov5/proto_data/images/val/*.jpg')\n",
        "\n",
        "for tf in train_files:\n",
        "  img = Image.open(tf)\n",
        "  img.thumbnail((640, 640), Image.ANTIALIAS)\n",
        "  img.save(\"/content/drive/MyDrive/test_yolov5/data/images/train/\" + os.path.basename(tf))\n",
        "\n",
        "for vf in val_files:\n",
        "  img = Image.open(vf)\n",
        "  img.thumbnail((640, 640), Image.ANTIALIAS)\n",
        "  img.save(\"/content/drive/MyDrive/test_yolov5/data/images/val/\" + os.path.basename(vf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이 코드는 로컬의 데이터를 /content/drive/MyDrive/test_yolov5/data/에 모두 업로드한 뒤 실행함. proto_data가 아님에 주의\n",
        "#레이블 복사\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "train_files = glob.glob('/content/drive/MyDrive/test_yolov5/proto_data/labels/train/*.txt')\n",
        "val_files = glob.glob('/content/drive/MyDrive/test_yolov5/proto_data/labels/val/*.txt')\n",
        "\n",
        "for tf in train_files:\n",
        "  tf_name = os.path.basename(tf)\n",
        "  shutil.copyfile(tf, os.path.join('/content/drive/MyDrive/test_yolov5/data/labels/train/', tf_name))\n",
        "\n",
        "for vf in val_files:\n",
        "  vf_name = os.path.basename(vf)\n",
        "  shutil.copyfile(vf, os.path.join('/content/drive/MyDrive/test_yolov5/data/labels/val/', vf_name))"
      ],
      "metadata": {
        "id": "uMwxzSew0qKp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hFXmPDcfnqwC"
      },
      "outputs": [],
      "source": [
        "#yaml 파일을 만져 데이터셋이 있는 경로를 변경해준다.\n",
        "#이전에 우선 data/dataset.yaml파일이 copy돼있는지, 그리고 dataset.yaml 파일을 직접 수정했는지 확인한다.\n",
        "import yaml\n",
        "\n",
        "shutil.copyfile('/content/drive/MyDrive/test_yolov5/proto_data/dataset.yaml', '/content/drive/MyDrive/test_yolov5/data/dataset.yaml')\n",
        "\n",
        "with open('/content/drive/MyDrive/test_yolov5/data/dataset.yaml', 'r') as f:\n",
        "  data = yaml.safe_load(f)\n",
        "\n",
        "data['names'] = ['Book', 'Calculator', 'Mobile phone', 'Pencil case', 'Postit']\n",
        "data['nc'] = 5\n",
        "data['train'] = '/content/drive/MyDrive/test_yolov5/data/images/train'\n",
        "data['val'] = '/content/drive/MyDrive/test_yolov5/data/images/val'\n",
        "\n",
        "#yolov5 공식문서와 달리 data 경로를 담은 txt가 아니라 디렉터리 자체를 지정했는데, \n",
        "#이는 txt 사용 시 마지막 model quantization에서 문제가 발생하기 때문\n",
        "\n",
        "with open('/content/drive/MyDrive/test_yolov5/data/dataset.yaml', 'w') as f:\n",
        "  yaml.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxn7viPuLQf5",
        "outputId": "a290947b-2222-4032-cfa7-7c8035f5f284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [--weights WEIGHTS] [--cfg CFG] [--data DATA] [--hyp HYP]\n",
            "                [--epochs EPOCHS] [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
            "                [--rect] [--resume [RESUME]] [--nosave] [--noval]\n",
            "                [--noautoanchor] [--noplots] [--evolve [EVOLVE]]\n",
            "                [--bucket BUCKET] [--cache [CACHE]] [--image-weights]\n",
            "                [--device DEVICE] [--multi-scale] [--single-cls]\n",
            "                [--optimizer {SGD,Adam,AdamW}] [--sync-bn] [--workers WORKERS]\n",
            "                [--project PROJECT] [--name NAME] [--exist-ok] [--quad]\n",
            "                [--cos-lr] [--label-smoothing LABEL_SMOOTHING]\n",
            "                [--patience PATIENCE] [--freeze FREEZE [FREEZE ...]]\n",
            "                [--save-period SAVE_PERIOD] [--local_rank LOCAL_RANK]\n",
            "                [--entity ENTITY] [--upload_dataset [UPLOAD_DATASET]]\n",
            "                [--bbox_interval BBOX_INTERVAL]\n",
            "                [--artifact_alias ARTIFACT_ALIAS]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --weights WEIGHTS     initial weights path\n",
            "  --cfg CFG             model.yaml path\n",
            "  --data DATA           dataset.yaml path\n",
            "  --hyp HYP             hyperparameters path\n",
            "  --epochs EPOCHS\n",
            "  --batch-size BATCH_SIZE\n",
            "                        total batch size for all GPUs, -1 for autobatch\n",
            "  --imgsz IMGSZ, --img IMGSZ, --img-size IMGSZ\n",
            "                        train, val image size (pixels)\n",
            "  --rect                rectangular training\n",
            "  --resume [RESUME]     resume most recent training\n",
            "  --nosave              only save final checkpoint\n",
            "  --noval               only validate final epoch\n",
            "  --noautoanchor        disable AutoAnchor\n",
            "  --noplots             save no plot files\n",
            "  --evolve [EVOLVE]     evolve hyperparameters for x generations\n",
            "  --bucket BUCKET       gsutil bucket\n",
            "  --cache [CACHE]       --cache images in \"ram\" (default) or \"disk\"\n",
            "  --image-weights       use weighted image selection for training\n",
            "  --device DEVICE       cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
            "  --multi-scale         vary img-size +/- 50%\n",
            "  --single-cls          train multi-class data as single-class\n",
            "  --optimizer {SGD,Adam,AdamW}\n",
            "                        optimizer\n",
            "  --sync-bn             use SyncBatchNorm, only available in DDP mode\n",
            "  --workers WORKERS     max dataloader workers (per RANK in DDP mode)\n",
            "  --project PROJECT     save to project/name\n",
            "  --name NAME           save to project/name\n",
            "  --exist-ok            existing project/name ok, do not increment\n",
            "  --quad                quad dataloader\n",
            "  --cos-lr              cosine LR scheduler\n",
            "  --label-smoothing LABEL_SMOOTHING\n",
            "                        Label smoothing epsilon\n",
            "  --patience PATIENCE   EarlyStopping patience (epochs without improvement)\n",
            "  --freeze FREEZE [FREEZE ...]\n",
            "                        Freeze layers: backbone=10, first3=0 1 2\n",
            "  --save-period SAVE_PERIOD\n",
            "                        Save checkpoint every x epochs (disabled if < 1)\n",
            "  --local_rank LOCAL_RANK\n",
            "                        DDP parameter, do not modify\n",
            "  --entity ENTITY       W&B: Entity\n",
            "  --upload_dataset [UPLOAD_DATASET]\n",
            "                        W&B: Upload data, \"val\" option\n",
            "  --bbox_interval BBOX_INTERVAL\n",
            "                        W&B: Set bounding-box image logging interval\n",
            "  --artifact_alias ARTIFACT_ALIAS\n",
            "                        W&B: Version of dataset artifact to use\n"
          ]
        }
      ],
      "source": [
        "#아래 명령어로 모델 훈련 시 실행할 수 있는 옵션들을 확인해보십시오.\n",
        "!python train.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDhQ3mm1mXKV",
        "outputId": "3ec461c2-5d56-481a-f42e-19660a1ad039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_yolov5/yolov5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwifihanstudy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=/content/drive/MyDrive/test_yolov5/yolov5/models/yolov5m.yaml, data=/content/drive/MyDrive/test_yolov5/data/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.2-80-g55b0096 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/test_yolov5/yolov5/wandb/run-20220901_024243-3uqlq1hf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-star-6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/wifihanstudy/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/wifihanstudy/YOLOv5/runs/3uqlq1hf\u001b[0m\n",
            "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     40410  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
            "YOLOv5m summary: 369 layers, 20887482 parameters, 20887482 gradients, 48.3 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/test_yolov5/data/labels/train.cache' images and labels... 466 found, 0 missing, 0 empty, 0 corrupt: 100% 466/466 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 466/466 [00:02<00:00, 160.93it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/test_yolov5/data/labels/val.cache' images and labels... 117 found, 0 missing, 0 empty, 0 corrupt: 100% 117/117 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 117/117 [00:01<00:00, 66.49it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.22 anchors/target, 0.998 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp6/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp6\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      12.1G     0.1063    0.03343    0.05094         55        640: 100% 15/15 [00:14<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.07s/it]\n",
            "                   all        117        166    0.00857      0.832     0.0529     0.0208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      11.7G    0.07578    0.03162    0.03953         61        640: 100% 15/15 [00:11<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.49s/it]\n",
            "                   all        117        166       0.25      0.499      0.267      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      12.6G     0.0601    0.02714    0.02969         76        640: 100% 15/15 [00:11<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.45s/it]\n",
            "                   all        117        166      0.173      0.354      0.172      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      12.6G    0.05629    0.02315    0.02382         50        640: 100% 15/15 [00:11<00:00,  1.29it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.40s/it]\n",
            "                   all        117        166      0.236      0.239      0.228      0.116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      12.6G    0.05237     0.0224    0.02007         58        640: 100% 15/15 [00:11<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.40s/it]\n",
            "                   all        117        166      0.207      0.388      0.226       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      12.6G    0.05042    0.02082    0.01937         42        640: 100% 15/15 [00:12<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.38s/it]\n",
            "                   all        117        166      0.261       0.68      0.387       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      12.6G    0.04532    0.02046    0.01596         68        640: 100% 15/15 [00:11<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.37s/it]\n",
            "                   all        117        166      0.301      0.642      0.465      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      12.6G    0.04606    0.02015    0.01295         73        640: 100% 15/15 [00:12<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.55s/it]\n",
            "                   all        117        166      0.387      0.447      0.468      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      12.6G    0.04023    0.01894    0.01076         54        640: 100% 15/15 [00:12<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.38s/it]\n",
            "                   all        117        166      0.376       0.39      0.433       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      12.6G    0.03589    0.01921    0.01098         63        640: 100% 15/15 [00:12<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.36s/it]\n",
            "                   all        117        166       0.53      0.554      0.597      0.474\n",
            "\n",
            "10 epochs completed in 0.052 hours.\n",
            "Optimizer stripped from runs/train/exp6/weights/last.pt, 42.3MB\n",
            "Optimizer stripped from runs/train/exp6/weights/best.pt, 42.3MB\n",
            "\n",
            "Validating runs/train/exp6/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 20869098 parameters, 0 gradients, 47.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.86s/it]\n",
            "                   all        117        166      0.531      0.554      0.598      0.475\n",
            "            Calculator        117          8      0.219      0.125      0.164      0.107\n",
            "          Mobile phone        117        147      0.805      0.537      0.747      0.553\n",
            "           Pencil case        117         11       0.57          1      0.884      0.765\n",
            "Results saved to \u001b[1mruns/train/exp6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▄▃▃▃▅▆▆▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▃▂▂▃▄▅▆▄██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▄▃▄▄▄▅▆▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall █▄▂▁▃▆▆▃▃▅▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▃▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▅▅▄▄▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▅▄▄▃▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▅▃▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▇▆▅▃▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▁▄▆▇██▇▇▅▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.59702\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.47445\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.52965\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.55414\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.59818\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.47507\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.53123\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.55414\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03589\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01098\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01921\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02571\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.008\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00829\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00208\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00208\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00208\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-star-6\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/wifihanstudy/YOLOv5/runs/3uqlq1hf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 335 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220901_024243-3uqlq1hf/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#학습: dataset의 train에 접근\n",
        "%cd /content/drive/MyDrive/test_yolov5/yolov5/\n",
        "\n",
        "#셀을 실행하면 자동으로 wandb 로그인이 아래 결과창에 뜨는데, wandb 로그인을 해야 훈련을 진행할 수 있음.\n",
        "#GPU 용량이 허락하는 한 batch 크기를 늘려 훈련 속도를 더 높일 수 있음.\n",
        "\n",
        "#yolov5 모델 있는 git url에 들어가면 설명이 상세히 나와있음.\n",
        "#cfg는 models의 구조. yolov5/models에 정리돼있는데, 4개의 yaml 파일 중 모델의 크기에 따라 구분됨.\n",
        "#yolov5m 가중치를 사용. 원하면 yolov5s cfg와 weights를 사용할 수 있음.\n",
        "#weights는 pre-trained된 가중치를 받아서 사용할 수도, cfg와 같이 custom model의 경로에 직접 접근해 .pt 모델을 사용할 수도 있음.\n",
        "!python train.py --img 640 --batch 32 --cache --epochs 10 --data /content/drive/MyDrive/test_yolov5/data/dataset.yaml --cfg /content/drive/MyDrive/test_yolov5/yolov5/models/yolov5m.yaml --weights yolov5m.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/new_yolov5/yolov5/\n",
        "!python export.py --h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcUNAuE6QSLN",
        "outputId": "36010a68-daab-4783-f926-92ee39030ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/new_yolov5/yolov5/'\n",
            "/content/drive/MyDrive/test_yolov5/yolov5\n",
            "usage: export.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
            "                 [--imgsz IMGSZ [IMGSZ ...]] [--batch-size BATCH_SIZE]\n",
            "                 [--device DEVICE] [--half] [--inplace] [--train] [--keras]\n",
            "                 [--optimize] [--int8] [--dynamic] [--simplify]\n",
            "                 [--opset OPSET] [--verbose] [--workspace WORKSPACE] [--nms]\n",
            "                 [--agnostic-nms] [--topk-per-class TOPK_PER_CLASS]\n",
            "                 [--topk-all TOPK_ALL] [--iou-thres IOU_THRES]\n",
            "                 [--conf-thres CONF_THRES] [--include INCLUDE [INCLUDE ...]]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --data DATA           dataset.yaml path\n",
            "  --weights WEIGHTS [WEIGHTS ...]\n",
            "                        model.pt path(s)\n",
            "  --imgsz IMGSZ [IMGSZ ...], --img IMGSZ [IMGSZ ...], --img-size IMGSZ [IMGSZ ...]\n",
            "                        image (h, w)\n",
            "  --batch-size BATCH_SIZE\n",
            "                        batch size\n",
            "  --device DEVICE       cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
            "  --half                FP16 half-precision export\n",
            "  --inplace             set YOLOv5 Detect() inplace=True\n",
            "  --train               model.train() mode\n",
            "  --keras               TF: use Keras\n",
            "  --optimize            TorchScript: optimize for mobile\n",
            "  --int8                CoreML/TF INT8 quantization\n",
            "  --dynamic             ONNX/TF: dynamic axes\n",
            "  --simplify            ONNX: simplify model\n",
            "  --opset OPSET         ONNX: opset version\n",
            "  --verbose             TensorRT: verbose log\n",
            "  --workspace WORKSPACE\n",
            "                        TensorRT: workspace size (GB)\n",
            "  --nms                 TF: add NMS to model\n",
            "  --agnostic-nms        TF: add agnostic NMS to model\n",
            "  --topk-per-class TOPK_PER_CLASS\n",
            "                        TF.js NMS: topk per class to keep\n",
            "  --topk-all TOPK_ALL   TF.js NMS: topk for all classes to keep\n",
            "  --iou-thres IOU_THRES\n",
            "                        TF.js NMS: IoU threshold\n",
            "  --conf-thres CONF_THRES\n",
            "                        TF.js NMS: confidence threshold\n",
            "  --include INCLUDE [INCLUDE ...]\n",
            "                        torchscript, onnx, openvino, engine, coreml,\n",
            "                        saved_model, pb, tflite, edgetpu, tfjs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyIzllPbvAxq",
        "outputId": "79e4fa46-7ce3-40aa-fea6-47ca0a0bc4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_yolov5/yolov5\n",
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=/content/drive/MyDrive/test_yolov5/data/dataset.yaml, weights=['/content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, train=False, keras=False, optimize=False, int8=True, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 🚀 v6.2-80-g55b0096 Python-3.7.13 torch-1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 20869098 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best.pt with output shape (1, 25200, 10) (40.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.8.2...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "2022-09-01 02:51:29.566799: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  1     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  1    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  1   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  1   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     40410  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 48)    5232        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 96)    41568       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 96)    64896       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_9 (TFConv)             (1, 80, 80, 192)     166080      ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 192)     443520      ['tf_conv_9[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_21 (TFConv)            (1, 40, 40, 384)     663936      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 384)     2509824     ['tf_conv_21[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_37 (TFConv)            (1, 20, 20, 768)     2654976     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 768)     4131840     ['tf_conv_37[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 768)     1475712     ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_47 (TFConv)            (1, 20, 20, 384)     295296      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 384)     0           ['tf_conv_47[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 768)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 384)     1181184     ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_55 (TFConv)            (1, 40, 40, 192)     73920       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 192)     0           ['tf_conv_55[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 384)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 192)     295680      ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_63 (TFConv)            (1, 40, 40, 192)     331968      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 384)     0           ['tf_conv_63[0][0]',             \n",
            "                                                                  'tf_conv_55[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 384)     1033728     ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_71 (TFConv)            (1, 20, 20, 384)     1327488     ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 768)     0           ['tf_conv_71[0][0]',             \n",
            "                                                                  'tf_conv_47[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 768)     4131840     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 10),     40410       ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 6400, 3, 10),               'tfc3_6[0][0]',                 \n",
            "                                 (1, 1600, 3, 10),                'tfc3_7[0][0]']                 \n",
            "                                 (1, 400, 3, 10)])                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,869,098\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,869,098\n",
            "__________________________________________________________________________________________________\n",
            "2022-09-01 02:51:40.064485: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "Assets written to: /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best_saved_model/assets\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 13.5s, saved as /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best_saved_model (79.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.8.2...\n",
            "Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 296). These functions will not be directly callable after loading.\n",
            "Assets written to: /tmp/tmpto27lc02/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "2022-09-01 02:53:01.461566: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2022-09-01 02:53:01.461625: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "Estimated count of arithmetic ops: 50.931 G  ops, equivalently 25.465 G  MACs\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n",
            "Estimated count of arithmetic ops: 50.931 G  ops, equivalently 25.465 G  MACs\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 353.6s, saved as /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best-int8.tflite (20.5 MB)\n",
            "\n",
            "Export complete (369.6s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights\u001b[0m\n",
            "Detect:          python detect.py --weights /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best-int8.tflite \n",
            "Validate:        python val.py --weights /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best-int8.tflite \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best-int8.tflite')\n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ],
      "source": [
        "# 모델 배포하기 \n",
        "# 모델 배포 과정에서 --int8 옵션을 넣어 저절로 quantization이 됨.\n",
        "\n",
        "%cd /content/drive/MyDrive/test_yolov5/yolov5/\n",
        "!python export.py --data /content/drive/MyDrive/test_yolov5/data/dataset.yaml --img 640 --conf 0.25 --weights /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp1/weights/best.pt --include tflite --int8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CExtEuELgl5Y",
        "outputId": "326bda9f-3b70-41ee-f4eb-99636ef883bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/test_yolov5/yolov5\n",
            "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
            "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
            "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
            "              [--device DEVICE] [--workers WORKERS] [--single-cls] [--augment]\n",
            "              [--verbose] [--save-txt] [--save-hybrid] [--save-conf]\n",
            "              [--save-json] [--project PROJECT] [--name NAME] [--exist-ok]\n",
            "              [--half] [--dnn]\n",
            "val.py: error: ambiguous option: --h could match --help, --half\n"
          ]
        }
      ],
      "source": [
        "# 검증 데이터셋을 이용한 성능 측정.\n",
        "%cd /content/drive/MyDrive/test_yolov5/yolov5/\n",
        "!python val.py --help"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb 사이트에 접속하여 train set에서의 성능과 validation set에서의 성능을 비교하면 overfitting 여부를 확인할 수 있다.\n",
        "# 그러나 시험 환경과 유사한 이미지 데이터에 대해 overfitting이 되는 것은 크게 상관없다.\n",
        "%cd /content/drive/MyDrive/test_yolov5/yolov5/\n",
        "!python val.py --img 640 --conf 0.25 --batch 64 --data /content/drive/MyDrive/test_yolov5/data/dataset.yaml --weights /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp1/weights/best-int8.tflite"
      ],
      "metadata": {
        "id": "mWwHmUGXAcwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a17628a-f6de-4699-8ce6-a75252692cfc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_yolov5/yolov5\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/test_yolov5/data/dataset.yaml, weights=['/content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best-int8.tflite'], batch_size=64, imgsz=640, conf_thres=0.25, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING: confidence threshold 0.25 > 0.001 produces invalid results ⚠️\n",
            "YOLOv5 🚀 v6.2-80-g55b0096 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Loading /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp6/weights/best-int8.tflite for TensorFlow Lite inference...\n",
            "Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/test_yolov5/data/labels/val.cache' images and labels... 117 found, 0 missing, 0 empty, 0 corrupt: 100% 117/117 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95:   2% 2/117 [03:15<3:07:09, 97.64s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"val.py\", line 397, in <module>\n",
            "    main(opt)\n",
            "  File \"val.py\", line 370, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"val.py\", line 207, in run\n",
            "    out, train_out = model(im) if training else model(im, augment=augment, val=True)  # inference, loss outputs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/test_yolov5/yolov5/models/common.py\", line 519, in forward\n",
            "    self.interpreter.invoke()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/interpreter.py\", line 916, in invoke\n",
            "    self._interpreter.Invoke()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시험 탐지: 별도의 source 필요\n",
        "%cd /content/drive/MyDrive/test_yolov5/yolov5/\n",
        "!python detect.py --help"
      ],
      "metadata": {
        "id": "Ds5nz4r7_9A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GPTqTHnB9Fj",
        "outputId": "f1fb6a90-742c-497e-ba01-3c8551e52924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/test_yolov5/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/new_yolov5/runs/train/20220523_1945003/weights/best-int8.tflite'], source=/content/drive/MyDrive/test_detect/20220512_165148.mp4, data=/content/drive/MyDrive/test5_mk_od/data/dataset.yaml, imgsz=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-251-gc23a441 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
            "\n",
            "Loading /content/drive/MyDrive/new_yolov5/runs/train/20220523_1945003/weights/best-int8.tflite for TensorFlow Lite inference...\n",
            "[{'name': 'StatefulPartitionedCall:0', 'index': 518, 'shape': array([    1, 25200,    10], dtype=int32), 'shape_signature': array([    1, 25200,    10], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.012042047455906868, 0), 'quantization_parameters': {'scales': array([   0.012042], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[[[ 1  1  3  3  0  3  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([[ 3.58371e+02,  2.77449e+02,  5.81872e+02,  3.69932e+02,  9.50837e-01,  2.00000e+00],\n",
            "        [-1.15603e+01,  7.70691e+00,  6.43527e+02,  1.31017e+02,  4.99418e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (1/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (64.102s)\n",
            "[[[ 1  1  3  3  0  4  3 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.084294    0.072252]]]\n",
            "tensor([[373.78516, 277.44876, 566.45789, 369.93167,   0.95084,   2.00000]], device='cuda:0')\n",
            "video 1/1 (2/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (64.023s)\n",
            "[[[ 1  1  3  3  0  3  2 46  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.55393    0.084294    0.072252]]]\n",
            "tensor([[373.78516, 277.44876, 566.45789, 369.93167,   0.95084,   2.00000]], device='cuda:0')\n",
            "video 1/1 (3/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (64.367s)\n",
            "[[[ 1  1  3  2  0  4  2 46 10  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.55393     0.12042    0.072252]]]\n",
            "tensor([[358.37134, 269.74188, 581.87170, 362.22479,   0.95084,   2.00000]], device='cuda:0')\n",
            "video 1/1 (4/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (64.062s)\n",
            "[[[ 1  1  3  3  0  4  2 46 10  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.55393     0.12042    0.072252]]]\n",
            "tensor([[373.78516, 277.44879, 566.45789, 354.51788,   0.95084,   2.00000]], device='cuda:0')\n",
            "video 1/1 (5/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.684s)\n",
            "[[[ 1  1  3  3  0  4  2 38 10  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.4576     0.12042     0.10838]]]\n",
            "tensor([[ 3.73785e+02,  2.77449e+02,  5.66458e+02,  3.54518e+02,  9.38801e-01,  2.00000e+00],\n",
            "        [-1.15603e+01,  7.70691e+00,  6.43527e+02,  1.31017e+02,  5.05508e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (6/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.781s)\n",
            "[[[ 1  1  3  3  0  4  3 42 10  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.50577     0.12042    0.072252]]]\n",
            "tensor([[ 3.62225e+02,  2.69742e+02,  5.78018e+02,  3.46811e+02,  9.38801e-01,  2.00000e+00],\n",
            "        [-1.15603e+01,  7.70691e+00,  6.43527e+02,  1.31017e+02,  5.05508e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (7/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (62.958s)\n",
            "[[[ 1  1  3  3  0  4  2 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021    0.084294    0.072252]]]\n",
            "tensor([[3.62225e+02, 2.73595e+02, 5.78018e+02, 3.42957e+02, 9.38801e-01, 2.00000e+00],\n",
            "        [1.54138e+01, 3.85345e+00, 6.31967e+02, 1.19457e+02, 4.33293e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (8/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (62.928s)\n",
            "[[[ 1  1  3  3  0  3  2 46  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.55393     0.10838    0.072252]]]\n",
            "tensor([[3.54518e+02, 2.73595e+02, 5.70311e+02, 3.42957e+02, 9.02693e-01, 2.00000e+00],\n",
            "        [1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.33293e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (9/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (62.776s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294    0.072252]]]\n",
            "tensor([[3.50664e+02, 2.77449e+02, 5.74165e+02, 3.39104e+02, 8.66585e-01, 2.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 5.05508e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (10/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.510s)\n",
            "[[[ 1  1  3  3  0  3  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([[3.50664e+02, 2.69742e+02, 5.74165e+02, 3.31397e+02, 9.14729e-01, 2.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 5.77724e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (11/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.736s)\n",
            "[[[ 1  1  3  3  0  3  3 42  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.50577    0.084294     0.10838]]]\n",
            "tensor([[342.95752, 265.88840, 566.45789, 319.83676,   0.84251,   2.00000],\n",
            "        [  7.70694,  11.56036, 624.25977, 127.16402,   0.72215,   1.00000]], device='cuda:0')\n",
            "video 1/1 (12/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (64.073s)\n",
            "[[[ 1  1  3  3  0  4  2 42  9  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.50577     0.10838     0.10838]]]\n",
            "tensor([[3.42958e+02, 2.65888e+02, 5.66458e+02, 3.19837e+02, 8.90657e-01, 2.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 5.77724e-01, 1.00000e+00],\n",
            "        [7.70694e+00, 5.54898e+02, 6.24260e+02, 6.31967e+02, 4.17631e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (13/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 2 Calculators, 1 Mobile phone, Done. (63.901s)\n",
            "[[[ 1  1  3  3  0  3  3 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021    0.084294    0.072252]]]\n",
            "tensor([[350.66443, 258.18149, 543.33716, 312.12985,   0.79437,   2.00000],\n",
            "        [  7.70694,  11.56036, 624.25977, 127.16402,   0.64994,   1.00000]], device='cuda:0')\n",
            "video 1/1 (14/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.780s)\n",
            "[[[ 1  1  3  3  0  3  2 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.55393    0.072252    0.084294]]]\n",
            "tensor([[3.50664e+02, 2.50475e+02, 5.43337e+02, 3.04423e+02, 6.61975e-01, 2.00000e+00],\n",
            "        [1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 5.05508e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (15/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.953s)\n",
            "[[[ 1  1  3  3  0  3  2 42  9  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.50577     0.10838    0.084294]]]\n",
            "tensor([[3.42958e+02, 2.42768e+02, 5.35630e+02, 2.96716e+02, 6.98083e-01, 2.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 5.05508e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (16/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.592s)\n",
            "[[[ 1  1  3  3  0  3  3 42  9  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.50577     0.10838    0.084294]]]\n",
            "tensor([[3.35251e+02, 2.35061e+02, 5.27923e+02, 2.89009e+02, 8.18442e-01, 2.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.33293e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (17/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.447s)\n",
            "[[[ 1  1  3  3  0  4  3 46  9  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393     0.10838    0.084294]]]\n",
            "tensor([[3.27544e+02, 2.27354e+02, 5.20216e+02, 2.81302e+02, 8.18442e-01, 2.00000e+00],\n",
            "        [7.70694e+00, 5.54898e+02, 6.24260e+02, 6.31967e+02, 4.28072e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (18/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Mobile phone, Done. (63.601s)\n",
            "[[[ 1  1  3  3  0  3  3 42  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.50577     0.10838    0.072252]]]\n",
            "tensor([[3.27544e+02, 2.19647e+02, 5.20216e+02, 2.73595e+02, 6.98083e-01, 2.00000e+00],\n",
            "        [7.70694e+00, 5.54898e+02, 6.24260e+02, 6.31967e+02, 4.99418e-01, 1.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.33293e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (19/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 2 Calculators, 1 Mobile phone, Done. (63.335s)\n",
            "[[[ 1  1  3  3  0  3  3 42  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.50577    0.084294    0.084294]]]\n",
            "tensor([[7.70694e+00, 5.54898e+02, 6.24260e+02, 6.31967e+02, 4.99418e-01, 1.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.33293e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (20/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 2 Calculators, Done. (63.662s)\n",
            "[[[ 1  1  3  3  0  3  3 34  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.40943    0.084294     0.12042]]]\n",
            "tensor([[7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.99418e-01, 1.00000e+00],\n",
            "        [7.70694e+00, 5.54898e+02, 6.24260e+02, 6.31967e+02, 4.22852e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (21/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 2 Calculators, Done. (63.174s)\n",
            "[[[ 1  1  3  3  0  4  3 34  9 10]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.40943     0.10838     0.12042]]]\n",
            "tensor([[7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.99418e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (22/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.954s)\n",
            "[[[ 1  1  3  2  0  4  3 42  6 10]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.50577    0.072252     0.12042]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (23/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.820s)\n",
            "[[[ 1  1  3  3  0  4  3 42  9  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.50577     0.10838     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (24/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.978s)\n",
            "[[[ 1  1  3  3  0  4  2 46  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.55393    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (25/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.125s)\n",
            "[[[ 1  1  3  3  0  3  2 50  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.072252     0.10838]]]\n",
            "tensor([[7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.28072e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (26/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.959s)\n",
            "[[[ 1  1  3  3  0  4  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (27/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.920s)\n",
            "[[[ 1  1  3  2  0  3  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (28/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.147s)\n",
            "[[[ 1  1  3  3  0  4  2 42  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.50577    0.084294     0.10838]]]\n",
            "tensor([[7.70694e+00, 5.35630e+02, 6.24260e+02, 6.51234e+02, 4.12411e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (29/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.736s)\n",
            "[[[ 1  1  3  3  0  4  2 50  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021     0.10838    0.072252]]]\n",
            "tensor([[7.70694e+00, 5.35630e+02, 6.24260e+02, 6.51234e+02, 4.12411e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (30/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.537s)\n",
            "[[[ 1  1  3  2  0  4  2 46  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.55393    0.084294     0.12042]]]\n",
            "tensor([[7.70694e+00, 5.27923e+02, 6.24260e+02, 6.43527e+02, 4.93327e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (31/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.086s)\n",
            "[[[ 1  1  3  3  0  3  2 46  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.55393    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (32/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.766s)\n",
            "[[[ 1  1  3  3  0  3  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (33/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.399s)\n",
            "[[[ 1  1  3  2  0  3  3 46  9  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393     0.10838     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (34/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.719s)\n",
            "[[[ 1  1  3  3  0  4  3 42  9  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.50577     0.10838    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (35/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.508s)\n",
            "[[[ 1  1  3  3  0  4  3 50  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021     0.10838    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (36/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.490s)\n",
            "[[[ 1  1  3  2  0  3  2 50  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021     0.10838    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (37/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.810s)\n",
            "[[[ 1  1  3  2  0  4  2 42  6 10]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.50577    0.072252     0.12042]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (38/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.101s)\n",
            "[[[ 1  1  3  2  0  4  2 46  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.55393    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (39/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.229s)\n",
            "[[[ 1  1  3  3  0  4  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (40/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.654s)\n",
            "[[[ 1  1  3  3  0  3  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (41/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.327s)\n",
            "[[[ 1  1  3  3  0  3  2 46  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.55393    0.084294     0.12042]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (42/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.628s)\n",
            "[[[ 1  1  3  3  0  3  2 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.084294    0.072252]]]\n",
            "tensor([[7.70694e+00, 5.27923e+02, 6.24260e+02, 6.43527e+02, 4.12411e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (43/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.699s)\n",
            "[[[ 1  1  3  2  0  4  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([[196.52621, 200.37965, 358.37131, 385.34552,   0.86659,   3.00000]], device='cuda:0')\n",
            "video 1/1 (44/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (63.257s)\n",
            "[[[ 1  1  3  3  0  3  2 54  9  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.10838     0.06021]]]\n",
            "tensor([[196.52621, 200.37965, 358.37131, 385.34552,   0.91473,   3.00000]], device='cuda:0')\n",
            "video 1/1 (45/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (63.261s)\n",
            "[[[ 1  1  3  3  0  4  2 50  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021     0.10838    0.072252]]]\n",
            "tensor([[196.52621, 200.37965, 358.37131, 385.34552,   0.91473,   3.00000]], device='cuda:0')\n",
            "video 1/1 (46/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.614s)\n",
            "[[[ 1  1  3  2  0  3  2 61  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.73456    0.072252    0.072252]]]\n",
            "tensor([[204.23312, 192.67274, 366.07822, 377.63861,   0.93880,   3.00000]], device='cuda:0')\n",
            "video 1/1 (47/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (63.338s)\n",
            "[[[ 1  1  3  2  0  3  2 58  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844    0.072252    0.072252]]]\n",
            "tensor([[204.23312, 192.67274, 366.07822, 377.63861,   0.86659,   3.00000]], device='cuda:0')\n",
            "video 1/1 (48/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (63.206s)\n",
            "[[[ 1  1  3  3  0  3  2 61  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.73456    0.084294     0.06021]]]\n",
            "tensor([[208.08658, 181.11238, 377.63858, 373.78516,   0.45736,   3.00000]], device='cuda:0')\n",
            "video 1/1 (49/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (63.413s)\n",
            "[[[ 1  1  3  3  0  4  2 58  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.69844    0.084294    0.072252]]]\n",
            "tensor([[200.37965, 181.11238, 385.34552, 373.78516,   0.40922,   3.00000]], device='cuda:0')\n",
            "video 1/1 (50/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (63.331s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (51/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.105s)\n",
            "[[[ 1  1  3  2  0  4  2 54  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027     0.10838    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (52/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.970s)\n",
            "[[[ 1  1  3  3  0  3  2 61  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.73456    0.084294     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (53/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.385s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (54/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.220s)\n",
            "[[[ 1  1  3  3  0  3  2 54  9  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.10838     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (55/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.337s)\n",
            "[[[ 1  1  3  3  0  3  2 58  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (56/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.305s)\n",
            "[[[ 1  1  3  3  0  4  2 54  9  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.65027     0.10838     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (57/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.074s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294    0.072252]]]\n",
            "tensor([[ 73.21565, 304.42294, 127.16402, 389.19894,   0.40922,   2.00000]], device='cuda:0')\n",
            "video 1/1 (58/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (62.999s)\n",
            "[[[ 1  1  3  3  0  4  2 54  9  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.65027     0.10838     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (59/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.939s)\n",
            "[[[ 1  1  3  3  0  4  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (60/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.219s)\n",
            "[[[ 1  1  3  3  0  3  3 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (61/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.157s)\n",
            "[[[ 1  1  3  3  0  4  3 46  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393     0.10838    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (62/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.406s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (63/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.420s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (64/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.242s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (65/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.266s)\n",
            "[[[ 1  1  3  3  0  4  2 46 10  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.55393     0.12042    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (66/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (61.987s)\n",
            "[[[ 1  1  3  2  0  4  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (67/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.177s)\n",
            "[[[ 1  1  3  3  0  3  2 58  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (68/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.516s)\n",
            "[[[ 1  1  3  3  0  4  2 50  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021     0.10838    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (69/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.664s)\n",
            "[[[ 1  1  3  2  0  3  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (70/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.180s)\n",
            "[[[ 1  1  3  3  0  4  2 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (71/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.721s)\n",
            "[[[ 1  1  3  3  0  4  3 46  9  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393     0.10838     0.06021]]]\n",
            "tensor([[7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.33293e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (72/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.758s)\n",
            "[[[ 1  1  3  3  0  4  3 46  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393    0.084294    0.084294]]]\n",
            "tensor([[7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.99418e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (73/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.197s)\n",
            "[[[ 1  1  3  2  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (74/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.137s)\n",
            "[[[ 1  1  3  3  0  3  2 61  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.73456    0.072252     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (75/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.828s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (76/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.806s)\n",
            "[[[ 1  1  3  3  0  4  2 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (77/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.268s)\n",
            "[[[ 1  1  3  2  0  3  2 46  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.55393    0.072252     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (78/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.052s)\n",
            "[[[ 1  1  3  2  0  3  2 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (79/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.124s)\n",
            "[[[ 1  1  3  2  0  3  2 61  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.73456     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (80/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.997s)\n",
            "[[[ 1  1  3  3  0  3  2 61  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.73456    0.072252     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (81/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.786s)\n",
            "[[[ 1  1  3  3  0  3  2 64  6  4]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.77069    0.072252    0.048168]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (82/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.207s)\n",
            "[[[ 1  1  3  2  0  3  2 67  4  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.80682    0.048168     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (83/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.445s)\n",
            "[[[ 1  1  3  3  0  3  2 64  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.77069    0.048168    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (84/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.667s)\n",
            "[[[ 1  1  3  3  0  3  2 61  5  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.73456     0.06021     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (85/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.603s)\n",
            "[[[ 1  1  3  3  0  4  3 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (86/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.322s)\n",
            "[[[ 1  1  3  2  0  4  2 46  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.55393    0.084294     0.12042]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (87/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.666s)\n",
            "[[[ 1  1  3  3  0  4  2 42  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.50577    0.084294     0.12042]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (88/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.793s)\n",
            "[[[ 1  1  3  3  0  4  2 46  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.55393    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (89/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.684s)\n",
            "[[[ 1  1  3  3  0  3  3 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (90/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.476s)\n",
            "[[[ 1  1  3  3  0  3  3 46  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.55393     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (91/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.914s)\n",
            "[[[ 1  1  3  2  0  4  3 42  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.50577    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (92/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.076s)\n",
            "[[[ 1  1  3  3  0  3  3 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.55393    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (93/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.438s)\n",
            "[[[ 1  1  3  2  0  4  3 38  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126      0.4576    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (94/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.133s)\n",
            "[[[ 1  1  3  3  0  4  3 42  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.50577    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (95/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.492s)\n",
            "[[[ 1  1  3  3  0  4  3 46  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (96/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.679s)\n",
            "[[[ 1  1  3  2  0  4  3 46  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.55393    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (97/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.912s)\n",
            "[[[ 1  1  3  3  0  4  3 42  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.50577    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (98/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.973s)\n",
            "[[[ 1  1  3  3  0  4  3 42  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.50577    0.084294     0.12042]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (99/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.341s)\n",
            "[[[ 1  1  3  3  0  4  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (100/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.469s)\n",
            "[[[ 1  1  3  2  0  4  3 50  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126      0.6021    0.072252     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (101/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.339s)\n",
            "[[[ 1  1  3  3  0  4  3 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (102/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.122s)\n",
            "[[[ 1  1  3  3  0  3  2 54  7  4]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.084294    0.048168]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (103/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.405s)\n",
            "[[[ 1  1  3  2  0  4  2 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084      0.6021    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (104/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.159s)\n",
            "[[[ 1  1  3  2  0  4  3 46  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.55393    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (105/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.365s)\n",
            "[[[ 1  1  3  2  0  4  2 50  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084      0.6021     0.10838    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (106/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.379s)\n",
            "[[[ 1  1  3  2  0  4  3 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126      0.6021    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (107/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.701s)\n",
            "[[[ 1  1  3  2  0  4  3 42  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.50577    0.072252     0.10838]]]\n",
            "tensor([[2.08087e+02, 2.46621e+02, 3.31397e+02, 4.31587e+02, 4.28072e-01, 3.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.12411e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (108/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (63.860s)\n",
            "[[[ 1  1  3  2  0  3  3 46  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393    0.072252     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (109/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.384s)\n",
            "[[[ 1  1  3  3  0  4  3 46  9  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393     0.10838    0.072252]]]\n",
            "tensor([[196.52621, 250.47456, 342.95749, 443.14734,   0.66197,   3.00000]], device='cuda:0')\n",
            "video 1/1 (110/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.158s)\n",
            "[[[ 1  1  3  2  0  3  3 46  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (111/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.128s)\n",
            "[[[ 1  1  3  2  0  4  2 42  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.50577    0.084294     0.12042]]]\n",
            "tensor([[1.73405e+02, 2.50475e+02, 3.50664e+02, 4.58561e+02, 9.14729e-01, 3.00000e+00],\n",
            "        [1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.28072e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (112/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (62.262s)\n",
            "[[[ 1  1  3  2  0  3  2 50  6 10]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.072252     0.12042]]]\n",
            "tensor([[1.73405e+02, 2.58181e+02, 3.50664e+02, 4.66268e+02, 9.38801e-01, 3.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.75056e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (113/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (62.499s)\n",
            "[[[ 1  1  3  2  0  3  2 50  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.072252     0.10838]]]\n",
            "tensor([[1.65699e+02, 2.77449e+02, 3.58371e+02, 4.62415e+02, 9.50837e-01, 3.00000e+00],\n",
            "        [7.70694e+00, 1.15604e+01, 6.24260e+02, 1.27164e+02, 4.38513e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (114/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (63.244s)\n",
            "[[[ 1  1  3  2  0  3  2 61  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.73456    0.072252     0.06021]]]\n",
            "tensor([[1.73405e+02, 2.96716e+02, 3.50664e+02, 4.43147e+02, 9.50837e-01, 3.00000e+00],\n",
            "        [1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.75056e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (115/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (62.947s)\n",
            "[[[ 1  1  3  3  0  3  2 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.084294    0.072252]]]\n",
            "tensor([[165.69856, 285.15570, 358.37134, 470.12152,   0.93880,   3.00000]], device='cuda:0')\n",
            "video 1/1 (116/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.583s)\n",
            "[[[ 1  1  3  3  0  3  2 58  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844     0.06021    0.084294]]]\n",
            "tensor([[1.73405e+02, 3.12130e+02, 3.50664e+02, 4.58561e+02, 9.38801e-01, 3.00000e+00],\n",
            "        [1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 5.05508e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (117/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (63.185s)\n",
            "[[[ 1  1  3  2  0  3  2 61  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.73456    0.072252     0.06021]]]\n",
            "tensor([[ 1.65699e+02,  2.92863e+02,  3.58371e+02,  4.77828e+02,  9.02693e-01,  3.00000e+00],\n",
            "        [ 1.54138e+01, -3.85345e+00,  6.31967e+02,  1.11750e+02,  4.33293e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (118/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (63.364s)\n",
            "[[[ 1  1  3  2  0  4  2 54  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027    0.084294    0.084294]]]\n",
            "tensor([[1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 5.70763e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (119/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.158s)\n",
            "[[[ 1  1  3  2  0  4  3 46  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.55393     0.06021     0.10838]]]\n",
            "tensor([[1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.81146e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (120/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.176s)\n",
            "[[[ 1  1  3  2  0  4  3 54  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.65027    0.084294    0.072252]]]\n",
            "tensor([[1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.17631e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (121/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.998s)\n",
            "[[[ 1  1  3  2  0  4  3 50  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126      0.6021    0.072252     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (122/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.053s)\n",
            "[[[ 1  1  3  2  0  4  2 54  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027    0.084294    0.072252]]]\n",
            "tensor([[1.65699e+02, 3.00570e+02, 3.58371e+02, 4.85535e+02, 5.05508e-01, 3.00000e+00],\n",
            "        [1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.28072e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (123/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, 1 Pencil case, Done. (62.945s)\n",
            "[[[ 1  1  3  3  0  4  3 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.072252    0.072252]]]\n",
            "tensor([[157.99165, 300.56952, 350.66443, 485.53534,   0.81844,   3.00000]], device='cuda:0')\n",
            "video 1/1 (124/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.987s)\n",
            "[[[ 1  1  3  3  0  4  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (125/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.678s)\n",
            "[[[ 1  1  3  3  0  3  2 58  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.072252     0.06021]]]\n",
            "tensor([[1.92673e+02, 3.35251e+02, 3.15983e+02, 4.50854e+02, 4.33293e-01, 3.00000e+00]], device='cuda:0')\n",
            "video 1/1 (126/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.681s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (127/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.566s)\n",
            "[[[ 1  1  3  2  0  4  2 50  7  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084      0.6021    0.084294    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (128/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.529s)\n",
            "[[[ 1  1  3  3  0  3  2 50  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021     0.06021     0.10838]]]\n",
            "tensor([[157.99165, 335.25061, 350.66443, 450.85425,   0.86659,   3.00000]], device='cuda:0')\n",
            "video 1/1 (129/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.624s)\n",
            "[[[ 1  1  3  2  0  4  2 54  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027    0.072252    0.084294]]]\n",
            "tensor([[192.67276, 335.25061, 315.98331, 450.85425,   0.64994,   3.00000]], device='cuda:0')\n",
            "video 1/1 (130/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.562s)\n",
            "[[[ 1  1  3  3  0  3  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([[157.99165, 335.25061, 350.66443, 450.85425,   0.64994,   3.00000]], device='cuda:0')\n",
            "video 1/1 (131/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.317s)\n",
            "[[[ 1  1  3  2  0  4  3 42  6 10]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.50577    0.072252     0.12042]]]\n",
            "tensor([[1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.28072e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (132/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.479s)\n",
            "[[[ 1  1  3  2  0  4  2 46  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.55393    0.072252     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (133/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.129s)\n",
            "[[[ 1  1  3  2  0  3  2 58  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844     0.06021    0.072252]]]\n",
            "tensor([[1.54138e+01, 1.15604e+01, 6.31967e+02, 1.27164e+02, 4.22852e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (134/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (62.464s)\n",
            "[[[ 1  1  3  3  0  4  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([[1.92673e+02, 3.35251e+02, 3.15983e+02, 4.50854e+02, 4.33293e-01, 3.00000e+00]], device='cuda:0')\n",
            "video 1/1 (135/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Pencil case, Done. (62.957s)\n",
            "[[[ 1  1  3  2  0  3  3 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (136/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.093s)\n",
            "[[[ 1  1  3  3  0  4  2 42  7 10]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084     0.50577    0.084294     0.12042]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (137/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.896s)\n",
            "[[[ 1  1  3  3  0  4  3 46  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (138/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.167s)\n",
            "[[[ 1  1  3  2  0  4  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (139/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.318s)\n",
            "[[[ 1  1  3  2  0  4  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (140/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.127s)\n",
            "[[[ 1  1  3  3  0  4  3 46  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (141/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.411s)\n",
            "[[[ 1  1  3  3  0  3  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (142/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.430s)\n",
            "[[[ 1  1  3  3  0  3  3 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (143/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.756s)\n",
            "[[[ 1  1  3  3  0  3  2 54  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (144/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.619s)\n",
            "[[[ 1  1  3  3  0  4  3 46  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393    0.072252     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (145/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.786s)\n",
            "[[[ 1  1  3  2  0  3  2 46  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.55393     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (146/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.863s)\n",
            "[[[ 1  1  3  3  0  4  2 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.024084      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (147/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.218s)\n",
            "[[[ 1  1  3  2  0  4  3 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.55393    0.072252    0.084294]]]\n",
            "tensor([[ 7.70694e+00, -3.85345e+00,  6.24260e+02,  1.11750e+02,  4.33293e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (148/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.037s)\n",
            "[[[ 1  1  3  2  0  3  2 54  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027    0.072252    0.084294]]]\n",
            "tensor([[7.70694e+00, 7.70691e+00, 6.24260e+02, 8.47760e+01, 5.05508e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (149/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.125s)\n",
            "[[[ 1  1  3  2  0  3  2 58  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844     0.06021    0.072252]]]\n",
            "tensor([[7.70694e+00, 7.70691e+00, 6.24260e+02, 8.47760e+01, 5.05508e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (150/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.294s)\n",
            "[[[ 1  1  3  2  0  3  2 61  6  4]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.73456    0.072252    0.048168]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (151/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.838s)\n",
            "[[[ 1  1  3  2  0  3  2 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027     0.06021    0.072252]]]\n",
            "tensor([[7.70694e+00, 7.70691e+00, 6.24260e+02, 8.47760e+01, 4.33293e-01, 1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (152/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.574s)\n",
            "[[[ 1  1  3  2  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([[ 7.70694e+00, -1.15604e+01,  6.24260e+02,  1.04043e+02,  4.33293e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (153/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.634s)\n",
            "[[[ 1  1  3  2  0  3  2 58  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844    0.048168    0.072252]]]\n",
            "tensor([[ 7.70694e+00, -3.85345e+00,  6.24260e+02,  1.11750e+02,  4.33293e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (154/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.421s)\n",
            "[[[ 1  1  3  2  0  3  2 64  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.77069    0.048168    0.072252]]]\n",
            "tensor([[ 7.70694e+00, -3.85345e+00,  6.24260e+02,  1.11750e+02,  4.33293e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (155/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.234s)\n",
            "[[[ 1  1  3  2  0  3  2 61  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.73456    0.048168    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (156/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.871s)\n",
            "[[[ 1  1  3  3  0  3  2 58  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (157/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.477s)\n",
            "[[[ 1  1  3  3  0  3  2 64  4  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.77069    0.048168     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (158/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.555s)\n",
            "[[[ 1  1  3  2  0  3  2 54  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (159/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.133s)\n",
            "[[[ 1  1  3  3  0  4  3 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (160/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.765s)\n",
            "[[[ 1  1  3  3  0  3  2 58  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (161/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.541s)\n",
            "[[[ 1  1  3  2  0  3  2 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (162/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.534s)\n",
            "[[[ 1  1  3  3  0  3  3 58  4  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.69844    0.048168     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (163/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.094s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (164/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.843s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([[5.89579e+02, 4.16173e+02, 6.43527e+02, 4.93242e+02, 4.21257e-01, 4.00000e+00]], device='cuda:0')\n",
            "video 1/1 (165/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Postit, Done. (62.823s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (166/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.498s)\n",
            "[[[ 1  1  3  3  0  3  2 54  4  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.048168     0.10838]]]\n",
            "tensor([[6.08846e+02, 4.00759e+02, 6.39674e+02, 4.77828e+02, 4.57364e-01, 4.00000e+00]], device='cuda:0')\n",
            "video 1/1 (167/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Postit, Done. (63.349s)\n",
            "[[[ 1  1  3  3  0  3  2 50  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.072252     0.10838]]]\n",
            "tensor([[ 7.70694e+00, -3.85345e+00,  6.24260e+02,  1.11750e+02,  4.33293e-01,  1.00000e+00]], device='cuda:0')\n",
            "video 1/1 (168/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Calculator, Done. (63.601s)\n",
            "[[[ 1  1  3  2  0  3  2 61  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.73456     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (169/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.356s)\n",
            "[[[ 1  1  3  3  0  3  2 58  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (170/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.166s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (171/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.118s)\n",
            "[[[ 1  1  3  3  0  4  3 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (172/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.424s)\n",
            "[[[ 1  1  3  3  0  3  2 58  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.048168    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (173/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.566s)\n",
            "[[[ 1  1  3  2  0  3  3 46  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (174/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.375s)\n",
            "[[[ 1  1  3  2  0  3  3 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (175/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.175s)\n",
            "[[[ 1  1  3  2  0  3  2 58  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (176/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.403s)\n",
            "[[[ 1  1  3  3  0  4  3 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (177/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.661s)\n",
            "[[[ 1  1  3  2  0  3  3 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (178/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.341s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (179/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.320s)\n",
            "[[[ 1  1  3  3  0  3  3 58  5  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.69844     0.06021     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (180/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.322s)\n",
            "[[[ 1  1  3  2  0  3  2 58  4  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844    0.048168    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (181/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.477s)\n",
            "[[[ 1  1  3  3  0  3  2 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (182/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.571s)\n",
            "[[[ 1  1  3  3  0  3  2 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (183/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.557s)\n",
            "[[[ 1  1  3  2  0  3  3 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (184/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.497s)\n",
            "[[[ 1  1  3  3  0  3  2 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (185/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.532s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (186/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.326s)\n",
            "[[[ 1  1  3  2  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (187/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.506s)\n",
            "[[[ 1  1  3  2  0  3  2 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (188/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.437s)\n",
            "[[[ 1  1  3  2  0  3  3 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (189/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.329s)\n",
            "[[[ 1  1  3  2  0  3  2 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (190/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.974s)\n",
            "[[[ 1  1  3  3  0  3  2 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (191/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (65.275s)\n",
            "[[[ 1  1  3  3  0  3  2 58  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.048168    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (192/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (65.265s)\n",
            "[[[ 1  1  3  2  0  3  3 50  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (193/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (65.519s)\n",
            "[[[ 1  1  3  2  0  4  2 46  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.55393    0.072252     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (194/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (66.658s)\n",
            "[[[ 1  1  3  2  0  3  3 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (195/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (64.408s)\n",
            "[[[ 1  1  3  2  0  3  2 54  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (196/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (64.500s)\n",
            "[[[ 1  1  3  2  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (197/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.828s)\n",
            "[[[ 1  1  3  2  0  3  3 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (198/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.727s)\n",
            "[[[ 1  1  3  3  0  4  3 42  7  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.50577    0.084294     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (199/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.639s)\n",
            "[[[ 1  1  3  3  0  3  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (200/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.681s)\n",
            "[[[ 1  1  3  2  0  3  2 50  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (201/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.596s)\n",
            "[[[ 1  1  3  2  0  4  2 54  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (202/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.539s)\n",
            "[[[ 1  1  3  3  0  3  3 54  4  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.65027    0.048168     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (203/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.500s)\n",
            "[[[ 1  1  3  2  0  3  3 58  4  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.69844    0.048168     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (204/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.487s)\n",
            "[[[ 1  1  3  3  0  3  3 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.55393    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (205/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.390s)\n",
            "[[[ 1  1  3  2  0  4  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (206/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.897s)\n",
            "[[[ 1  1  3  2  0  3  2 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (207/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.104s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (208/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.941s)\n",
            "[[[ 1  1  3  2  0  3  3 50  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (209/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.063s)\n",
            "[[[ 1  1  3  2  0  3  2 50  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (210/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.781s)\n",
            "[[[ 1  1  3  2  0  3  3 50  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (211/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.330s)\n",
            "[[[ 1  1  3  2  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (212/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.762s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (213/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.478s)\n",
            "[[[ 1  1  3  2  0  3  3 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (214/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.226s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (215/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.940s)\n",
            "[[[ 1  1  3  2  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (216/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.506s)\n",
            "[[[ 1  1  3  2  0  3  3 54  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.65027    0.072252     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (217/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.413s)\n",
            "[[[ 1  1  3  2  0  4  3 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.55393    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (218/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.211s)\n",
            "[[[ 1  1  3  2  0  3  3 58  5  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.69844     0.06021     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (219/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.346s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (220/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.477s)\n",
            "[[[ 1  1  3  2  0  4  3 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (221/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.532s)\n",
            "[[[ 1  1  3  3  0  3  2 61  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.73456    0.048168    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (222/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.786s)\n",
            "[[[ 1  1  3  2  0  3  2 58  5  5]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844     0.06021     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (223/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.834s)\n",
            "[[[ 1  1  3  3  0  3  2 58  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (224/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.825s)\n",
            "[[[ 1  1  3  2  0  4  2 61  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.73456    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (225/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.720s)\n",
            "[[[ 1  1  3  3  0  3  2 58  5  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844     0.06021     0.06021]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (226/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.744s)\n",
            "[[[ 1  1  3  3  0  3  3 54  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.65027     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (227/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.598s)\n",
            "[[[ 1  1  3  2  0  3  2 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (228/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.876s)\n",
            "[[[ 1  1  3  2  0  3  2 58  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (229/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (64.687s)\n",
            "[[[ 1  1  3  2  0  3  2 54  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (230/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (65.872s)\n",
            "[[[ 1  1  3  2  0  3  2 58  4  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844    0.048168     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (231/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (65.154s)\n",
            "[[[ 1  1  3  3  0  3  2 50  7  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084      0.6021    0.084294    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (232/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (65.828s)\n",
            "[[[ 1  1  3  3  0  3  3 58  4  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.69844    0.048168    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (233/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (65.544s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([[562.60443, 339.10406, 639.67352, 400.75934,   0.77030,   2.00000]], device='cuda:0')\n",
            "video 1/1 (234/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (64.708s)\n",
            "[[[ 1  1  3  3  0  3  2 58  6  5]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.69844    0.072252     0.06021]]]\n",
            "tensor([[554.89752, 346.81097, 631.96661, 408.46625,   0.89066,   2.00000]], device='cuda:0')\n",
            "video 1/1 (235/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.405s)\n",
            "[[[ 1  1  3  3  0  3  2 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.06021    0.084294]]]\n",
            "tensor([[543.33716, 346.81097, 643.52698, 408.46625,   0.95084,   2.00000]], device='cuda:0')\n",
            "video 1/1 (236/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.234s)\n",
            "[[[ 1  1  3  2  0  3  2 58  4  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.69844    0.048168    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (237/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.243s)\n",
            "[[[ 1  1  3  2  0  4  3 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (238/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.370s)\n",
            "[[[ 1  1  3  2  0  3  2 50  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (239/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.811s)\n",
            "[[[ 1  1  3  2  0  3  2 54  4  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084     0.65027    0.048168    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (240/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.343s)\n",
            "[[[ 1  1  3  3  0  3  3 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (241/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.762s)\n",
            "[[[ 1  1  3  3  0  3  3 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (242/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.261s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (243/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.247s)\n",
            "[[[ 1  1  3  3  0  3  2 61  5  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.73456     0.06021    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (244/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.764s)\n",
            "[[[ 1  1  3  2  0  3  2 50  6  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.024084      0.6021    0.072252     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (245/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.642s)\n",
            "[[[ 1  1  3  3  0  3  3 50  4  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021    0.048168     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (246/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.777s)\n",
            "[[[ 1  1  3  2  0  4  2 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.024084     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (247/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.951s)\n",
            "[[[ 1  1  3  3  0  3  2 54  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027    0.072252    0.072252]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (248/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.901s)\n",
            "[[[ 1  1  3  2  0  3  3 46  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393     0.06021    0.084294]]]\n",
            "tensor([[5.43337e+02, 3.58371e+02, 6.43527e+02, 4.12320e+02, 6.25867e-01, 2.00000e+00]], device='cuda:0')\n",
            "video 1/1 (249/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.044s)\n",
            "[[[ 1  1  3  3  0  4  3 50  6  6]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021    0.072252    0.072252]]]\n",
            "tensor([[543.33716, 358.37134, 643.52698, 412.31970,   0.81844,   2.00000]], device='cuda:0')\n",
            "video 1/1 (250/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.058s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([[562.60443, 358.37134, 639.67352, 412.31970,   0.91473,   2.00000]], device='cuda:0')\n",
            "video 1/1 (251/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.139s)\n",
            "[[[ 1  1  3  3  0  3  3 50  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021    0.072252    0.084294]]]\n",
            "tensor([[562.60443, 358.37134, 639.67352, 412.31970,   0.92676,   2.00000]], device='cuda:0')\n",
            "video 1/1 (252/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (62.899s)\n",
            "[[[ 1  1  3  2  0  3  3 50  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126      0.6021     0.06021     0.10838]]]\n",
            "tensor([[562.60443, 358.37134, 639.67352, 412.31970,   0.89066,   2.00000]], device='cuda:0')\n",
            "video 1/1 (253/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (62.921s)\n",
            "[[[ 1  1  3  2  0  3  3 46  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393     0.06021    0.084294]]]\n",
            "tensor([[5.78018e+02, 3.58371e+02, 6.39674e+02, 4.12320e+02, 4.21257e-01, 2.00000e+00]], device='cuda:0')\n",
            "video 1/1 (254/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.150s)\n",
            "[[[ 1  1  3  3  0  3  3 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126     0.65027     0.06021    0.084294]]]\n",
            "tensor([[578.01825, 358.37134, 639.67352, 412.31970,   0.79437,   2.00000]], device='cuda:0')\n",
            "video 1/1 (255/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (62.862s)\n",
            "[[[ 1  1  3  2  0  4  3 42  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126     0.50577    0.072252    0.084294]]]\n",
            "tensor([[5.78018e+02, 3.58371e+02, 6.39674e+02, 4.12320e+02, 4.21257e-01, 2.00000e+00]], device='cuda:0')\n",
            "video 1/1 (256/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.100s)\n",
            "[[[ 1  1  3  3  0  4  3 46  6  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126     0.55393    0.072252    0.084294]]]\n",
            "tensor([[5.81872e+02, 3.58371e+02, 6.35820e+02, 4.12320e+02, 4.09221e-01, 2.00000e+00]], device='cuda:0')\n",
            "video 1/1 (257/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (63.150s)\n",
            "[[[ 1  1  3  3  0  4  3 50  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (258/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.865s)\n",
            "[[[ 1  1  3  2  0  3  3 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (259/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.971s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([[585.72516, 354.51788, 647.38043, 400.75934,   0.79437,   2.00000]], device='cuda:0')\n",
            "video 1/1 (260/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (62.432s)\n",
            "[[[ 1  1  3  2  0  4  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.048168    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([[578.01825, 350.66443, 639.67352, 404.61279,   0.69808,   2.00000]], device='cuda:0')\n",
            "video 1/1 (261/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 1 Mobile phone, Done. (62.747s)\n",
            "[[[ 1  1  3  2  0  3  3 46  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      15.414           0    0.036126    0.036126     0.55393     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (262/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (63.012s)\n",
            "[[[ 1  1  3  3  0  3  3 50  5  9]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.036126      0.6021     0.06021     0.10838]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (263/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.727s)\n",
            "[[[ 1  1  3  3  0  4  3 50  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.048168    0.036126      0.6021     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (264/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.743s)\n",
            "[[[ 1  1  3  3  0  3  2 54  5  7]]]\n",
            "[[[     7.7069      7.7069      23.121      23.121           0    0.036126    0.024084     0.65027     0.06021    0.084294]]]\n",
            "tensor([], device='cuda:0', size=(0, 6))\n",
            "video 1/1 (265/265) /content/drive/.shortcut-targets-by-id/10NptF8SByCfLxhPaEiZzFKNYzF-G2Ul5/test_detect/20220512_165148.mp4: 640x640 Done. (62.484s)\n",
            "Speed: 15.2ms pre-process, 63203.6ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp19\u001b[0m\n",
            "82 labels saved to runs/detect/exp19/labels\n"
          ]
        }
      ],
      "source": [
        "# source는 이미지 폴더가 될 수도, youtube 영상이 될 수도 있음.\n",
        "# 가중치로 quantization 이전 .pt 모델을 사용하면 정상적인 속도로 추론되나, 이 코드와 같이 quantize된 .tflite모델을 사용하면 추론 속도가 매우 느림.\n",
        "# 이는 uint8 quantization 모델의 추론이 가장 잘 작동하는 환경이 ARM 프로세서로, 추론 환경이 다르기 때문. 모바일에서는 정상적으로 작동함.\n",
        "%cd /content/drive/MyDrive/test_yolov5/yolov5/\n",
        "!python detect.py --save-txt --save-conf --data /content/drive/MyDrive/test5_mk_od/data/dataset.yaml --weights /content/drive/MyDrive/test_yolov5/yolov5/runs/train/exp1/weights/best-int8.tflite --img 640 --conf 0.4 --source #"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}